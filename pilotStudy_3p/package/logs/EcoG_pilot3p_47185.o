no change     /scratch/connectome/ahhyun724/fsl/condabin/conda
no change     /scratch/connectome/ahhyun724/fsl/bin/conda
no change     /scratch/connectome/ahhyun724/fsl/bin/conda-env
no change     /scratch/connectome/ahhyun724/fsl/bin/activate
no change     /scratch/connectome/ahhyun724/fsl/bin/deactivate
no change     /scratch/connectome/ahhyun724/fsl/etc/profile.d/conda.sh
no change     /scratch/connectome/ahhyun724/fsl/etc/fish/conf.d/conda.fish
no change     /scratch/connectome/ahhyun724/fsl/shell/condabin/Conda.psm1
no change     /scratch/connectome/ahhyun724/fsl/shell/condabin/conda-hook.ps1
no change     /scratch/connectome/ahhyun724/fsl/lib/python3.11/site-packages/xontrib/conda.xsh
no change     /scratch/connectome/ahhyun724/fsl/etc/profile.d/conda.csh
no change     /home/connectome/ahhyun724/.bashrc
No action taken.
/scratch/connectome/ahhyun724/DIVER/torcheeg/pilotStudy_3p/package
node3
Fri 24 Jan 2025 02:26:05 PM KST
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.0, ver=1, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 1, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 4, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=0, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=10, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=20, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=30, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=40, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=fixation_normalized, stft=halfoverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_denormed, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=halfoverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=0, dsr=, mask=49, agg=sub_agg, norm=whole_trial_normalized, stft=nooverlap_halfnfft on GPU 1...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Model Summary: {'model_name': 'EEGNet', 'model_ver': 0, 'downsampling_rate': 2, 'dropout': 0.5, 'num_classes': 2}
criterion:  CrossEntropyLoss() optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.001
)
Training EEGNet for 20 epochs with batch size 32...
Running experiment: lr=0.0001, wd=0.001, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=base on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfnfft on GPU 0...
Running experiment: lr=0.0001, wd=0.001, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=nooverlap_halfnfft on GPU 1...
Running experiment: lr=0.0001, wd=0.001, ver=1, dsr=, mask=0, agg=sub_agg, norm=fixation_denormed, stft=halfoverlap_halfnfft on GPU 1...
