{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stft', 'raw_timeseries_label.npy', 'raw_timeseries_data.npy', 'normalized_timeseries', 'masks']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# List files in the specified directory\n",
    "dataset_path = '/scratch/connectome/dyhan316/ECOG_PILOT/data_rearranged/subject-aggregated'\n",
    "files = os.listdir(dataset_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mask_path = os.path.join(dataset_path, 'masks/mask_0.npy')\n",
    "mask = np.load(mask_path)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "label_path=os.path.join(dataset_path, 'raw_timeseries_label.npy')\n",
    "labels=np.load(label_path)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 10000)\n"
     ]
    }
   ],
   "source": [
    "data_path=os.path.join(dataset_path, 'normalized_timeseries/whole_trial_denormed_timeseries_data.npy')\n",
    "data=np.load(data_path)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchvision import transforms, utils\n",
    "import pandas as pd\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root_dir, data, label, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.data = np.load(os.path.join(root_dir, data))\n",
    "        self.label = np.load(os.path.join(root_dir, label))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def init_io(self):\n",
    "        self.info = pd.DataFrame({\n",
    "                \"subject_id\": [1],\n",
    "                \"trial_id\": [1],\n",
    "                \"duration\": [10000],\n",
    "                \"_record_id\": [\"_record_0\"]\n",
    "            })\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_data = torch.tensor(self.data[idx], dtype=torch.float32)  # Ensure data is float32\n",
    "        sample_label = torch.tensor(self.label[idx], dtype=torch.float32)  # Ensure label is float32\n",
    "        \n",
    "        if self.transform:\n",
    "            sample_data = self.transform(sample_data)\n",
    "        \n",
    "        return sample_data, sample_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch import float32\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.to(torch.float32))  # Ensure data is float32\n",
    "])\n",
    "\n",
    "dataset = MyDataset(dataset_path,  'normalized_timeseries/whole_trial_denormed_timeseries_data.npy', 'raw_timeseries_label.npy', transform=transform)\n",
    "dataset.init_io()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tensor type: torch.float32\n",
      "Label tensor type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "data_tensor, label_tensor = dataset[0]\n",
    "print(f\"Data tensor type: {data_tensor.dtype}\") #should be float32 \n",
    "print(f\"Label tensor type: {label_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 252\n",
      "Test set size: 108\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "mask_path=os.path.join(dataset_path, 'masks/mask_0.npy')\n",
    "mask = np.load(mask_path)\n",
    "\n",
    "# Create train and test indices based on the mask\n",
    "train_indices = np.where(mask == 0)[0]\n",
    "test_indices = np.where(mask == 1)[0]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, label = zip(*batch)\n",
    "    data = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).unsqueeze(1)  # Add electrode dimension\n",
    "    #data = data.unsqueeze(1) #only for EEGNet\n",
    "    #data = data[:,:,:,::4]\n",
    "    data = data.unsqueeze(-1) #only for Conformer ; [32,1,10000] -> [32,1,10000,1]\n",
    "    label = torch.stack([torch.tensor(l, dtype=torch.long) for l in label])\n",
    "    return data, label\n",
    "\n",
    "\n",
    "# Create train and test subsets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create DataLoader for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Print the sizes of the train and test sets\n",
    "print(f\"Train set size: {len(train_loader.dataset)}\")\n",
    "print(f\"Test set size: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([32, 1, 10000, 1])\n",
      "Targets shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3653884/1674521881.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).unsqueeze(1)  # Add electrode dimension\n",
      "/tmp/ipykernel_3653884/1674521881.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.stack([torch.tensor(l, dtype=torch.long) for l in label])\n"
     ]
    }
   ],
   "source": [
    "#checking the first batch size\n",
    "for batch in train_loader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Inputs shape: {inputs.shape}\")\n",
    "    print(f\"Targets shape: {targets.shape}\")\n",
    "    break  # Inspect only the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT MODEL\n",
    "- EEGNet, Conformer, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3653884/2902223590.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).unsqueeze(1)  # Add electrode dimension\n",
      "/tmp/ipykernel_3653884/2902223590.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.stack([torch.tensor(l, dtype=torch.long) for l in label])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0586, -0.4181],\n",
       "        [ 0.5104, -0.2978],\n",
       "        [ 0.1750,  0.4061],\n",
       "        [ 0.1509, -0.3642],\n",
       "        [-0.1279,  0.3282],\n",
       "        [-0.4743, -0.3656],\n",
       "        [ 0.3800,  0.7158],\n",
       "        [ 0.3142, -0.1223],\n",
       "        [ 0.1418,  0.0324],\n",
       "        [ 0.3105, -0.0989],\n",
       "        [ 0.1427, -0.7733],\n",
       "        [-0.0926,  0.5425],\n",
       "        [ 0.0385, -0.2724],\n",
       "        [-0.1617,  0.1390],\n",
       "        [-0.2566, -0.2032],\n",
       "        [ 0.7706,  0.2829],\n",
       "        [ 0.3506,  0.0988],\n",
       "        [ 0.3781, -0.1606],\n",
       "        [ 0.6032, -0.1246],\n",
       "        [-0.1617, -0.3197],\n",
       "        [-0.0868, -0.8267],\n",
       "        [-1.3394, -0.2059],\n",
       "        [-0.1805,  0.0027],\n",
       "        [ 0.2835,  0.2025],\n",
       "        [ 0.2394, -0.2079],\n",
       "        [ 0.1609, -0.2330],\n",
       "        [-0.0209,  0.0512],\n",
       "        [-0.2421,  0.3475],\n",
       "        [ 0.4854, -1.0294],\n",
       "        [-0.0884,  0.3530],\n",
       "        [ 0.1291, -0.0427],\n",
       "        [ 0.4217, -0.1320]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model definition, make sure to start from here when new training is needed\n",
    "from torcheeg.models import EEGNet\n",
    "\n",
    "model = EEGNet(chunk_size=2500,\n",
    "               num_electrodes=1,\n",
    "               dropout=0.5,\n",
    "               kernel_1=64,\n",
    "               kernel_2=16,\n",
    "               F1=8,\n",
    "               F2=16,\n",
    "               D=2,\n",
    "               num_classes=2)\n",
    "x, y = next(iter(train_loader))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3653884/1674521881.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).unsqueeze(1)  # Add electrode dimension\n",
      "/tmp/ipykernel_3653884/1674521881.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.stack([torch.tensor(l, dtype=torch.long) for l in label])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (10000 x 1). Kernel size: (1 x 25). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 15\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Conformer(num_electrodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m                   sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m501\u001b[39m,\n\u001b[1;32m      6\u001b[0m                   hid_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m                   forward_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     12\u001b[0m                   num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     14\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/DIVER/torcheeg/torcheeg/torcheeg/models/transformer/conformer.py:262\u001b[0m, in \u001b[0;36mConformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 262\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m    264\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/DIVER/torcheeg/torcheeg/torcheeg/models/transformer/conformer.py:37\u001b[0m, in \u001b[0;36mPatchEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     36\u001b[0m     b, _, _, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshallownet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(x)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/connectome/ahhyun724/.conda/envs/torcheeg/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (10000 x 1). Kernel size: (1 x 25). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "# model definition, make sure to start from here when new training is needed\n",
    "from torcheeg.models import Conformer\n",
    "\n",
    "model = Conformer(num_electrodes=1,\n",
    "                  sampling_rate=501,\n",
    "                  hid_channels=150,\n",
    "                  depth=6,\n",
    "                  heads=10,\n",
    "                  dropout=0.5,\n",
    "                  forward_expansion=4,\n",
    "                  forward_dropout=0.5,\n",
    "                  num_classes=2)\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3653884/2902223590.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).unsqueeze(1)  # Add electrode dimension\n",
      "/tmp/ipykernel_3653884/2902223590.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.stack([torch.tensor(l, dtype=torch.long) for l in label])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7409\n",
      "Epoch [2/100], Loss: 0.6786\n",
      "Epoch [3/100], Loss: 0.6606\n",
      "Epoch [4/100], Loss: 0.6333\n",
      "Epoch [5/100], Loss: 0.6164\n",
      "Epoch [6/100], Loss: 0.5875\n",
      "Epoch [7/100], Loss: 0.5636\n",
      "Epoch [8/100], Loss: 0.5966\n",
      "Epoch [9/100], Loss: 0.5670\n",
      "Epoch [10/100], Loss: 0.5413\n",
      "Epoch [11/100], Loss: 0.5223\n",
      "Epoch [12/100], Loss: 0.5200\n",
      "Epoch [13/100], Loss: 0.5221\n",
      "Epoch [14/100], Loss: 0.4936\n",
      "Epoch [15/100], Loss: 0.5120\n",
      "Epoch [16/100], Loss: 0.4839\n",
      "Epoch [17/100], Loss: 0.5066\n",
      "Epoch [18/100], Loss: 0.5162\n",
      "Epoch [19/100], Loss: 0.5030\n",
      "Epoch [20/100], Loss: 0.4640\n",
      "Epoch [21/100], Loss: 0.4450\n",
      "Epoch [22/100], Loss: 0.4775\n",
      "Epoch [23/100], Loss: 0.4360\n",
      "Epoch [24/100], Loss: 0.4755\n",
      "Epoch [25/100], Loss: 0.4700\n",
      "Epoch [26/100], Loss: 0.4535\n",
      "Epoch [27/100], Loss: 0.4674\n",
      "Epoch [28/100], Loss: 0.4753\n",
      "Epoch [29/100], Loss: 0.4393\n",
      "Epoch [30/100], Loss: 0.4676\n",
      "Epoch [31/100], Loss: 0.4593\n",
      "Epoch [32/100], Loss: 0.4486\n",
      "Epoch [33/100], Loss: 0.4271\n",
      "Epoch [34/100], Loss: 0.4883\n",
      "Epoch [35/100], Loss: 0.4318\n",
      "Epoch [36/100], Loss: 0.4496\n",
      "Epoch [37/100], Loss: 0.4382\n",
      "Epoch [38/100], Loss: 0.4392\n",
      "Epoch [39/100], Loss: 0.4423\n",
      "Epoch [40/100], Loss: 0.4263\n",
      "Epoch [41/100], Loss: 0.4116\n",
      "Epoch [42/100], Loss: 0.4028\n",
      "Epoch [43/100], Loss: 0.4287\n",
      "Epoch [44/100], Loss: 0.4246\n",
      "Epoch [45/100], Loss: 0.4260\n",
      "Epoch [46/100], Loss: 0.3989\n",
      "Epoch [47/100], Loss: 0.3747\n",
      "Epoch [48/100], Loss: 0.4167\n",
      "Epoch [49/100], Loss: 0.4283\n",
      "Epoch [50/100], Loss: 0.3894\n",
      "Epoch [51/100], Loss: 0.4345\n",
      "Epoch [52/100], Loss: 0.3735\n",
      "Epoch [53/100], Loss: 0.3762\n",
      "Epoch [54/100], Loss: 0.3798\n",
      "Epoch [55/100], Loss: 0.4162\n",
      "Epoch [56/100], Loss: 0.3899\n",
      "Epoch [57/100], Loss: 0.3943\n",
      "Epoch [58/100], Loss: 0.4026\n",
      "Epoch [59/100], Loss: 0.3693\n",
      "Epoch [60/100], Loss: 0.3637\n",
      "Epoch [61/100], Loss: 0.4140\n",
      "Epoch [62/100], Loss: 0.3575\n",
      "Epoch [63/100], Loss: 0.3916\n",
      "Epoch [64/100], Loss: 0.4065\n",
      "Epoch [65/100], Loss: 0.4167\n",
      "Epoch [66/100], Loss: 0.4006\n",
      "Epoch [67/100], Loss: 0.4056\n",
      "Epoch [68/100], Loss: 0.3464\n",
      "Epoch [69/100], Loss: 0.3402\n",
      "Epoch [70/100], Loss: 0.3667\n",
      "Epoch [71/100], Loss: 0.3877\n",
      "Epoch [72/100], Loss: 0.3644\n",
      "Epoch [73/100], Loss: 0.3714\n",
      "Epoch [74/100], Loss: 0.3515\n",
      "Epoch [75/100], Loss: 0.3849\n",
      "Epoch [76/100], Loss: 0.4154\n",
      "Epoch [77/100], Loss: 0.3855\n",
      "Epoch [78/100], Loss: 0.3357\n",
      "Epoch [79/100], Loss: 0.3918\n",
      "Epoch [80/100], Loss: 0.3601\n",
      "Epoch [81/100], Loss: 0.3266\n",
      "Epoch [82/100], Loss: 0.3302\n",
      "Epoch [83/100], Loss: 0.3517\n",
      "Epoch [84/100], Loss: 0.3380\n",
      "Epoch [85/100], Loss: 0.3401\n",
      "Epoch [86/100], Loss: 0.3994\n",
      "Epoch [87/100], Loss: 0.3389\n",
      "Epoch [88/100], Loss: 0.3651\n",
      "Epoch [89/100], Loss: 0.3683\n",
      "Epoch [90/100], Loss: 0.3246\n",
      "Epoch [91/100], Loss: 0.3673\n",
      "Epoch [92/100], Loss: 0.3247\n",
      "Epoch [93/100], Loss: 0.3587\n",
      "Epoch [94/100], Loss: 0.3135\n",
      "Epoch [95/100], Loss: 0.3600\n",
      "Epoch [96/100], Loss: 0.3288\n",
      "Epoch [97/100], Loss: 0.3508\n",
      "Epoch [98/100], Loss: 0.3407\n",
      "Epoch [99/100], Loss: 0.3907\n",
      "Epoch [100/100], Loss: 0.3074\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.float(), labels.long()  # Ensure proper types\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.75\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1])\n",
      "Test Accuracy: 39.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3653884/2902223590.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).unsqueeze(1)  # Add electrode dimension\n",
      "/tmp/ipykernel_3653884/2902223590.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.stack([torch.tensor(l, dtype=torch.long) for l in label])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    label_sum=0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.float(), labels.long()  # Ensure proper types\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            predictions = torch.argmax(outputs, dim=1)  # Get predicted class\n",
    "            correct += (predictions == labels).sum().item()  # Count correct predictions\n",
    "            total += labels.size(0)  # Total samples\n",
    "            label_sum += labels.sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(label_sum/len(test_loader))\n",
    "    print(labels)\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = evaluate_model(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcheeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
